{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Simulation (Sanjida)"
      ],
      "metadata": {
        "id": "mpt2gFMBEjJm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLsqsxMsEewL"
      },
      "outputs": [],
      "source": [
        "RUN_LLM = False                # True to load Mistral / generate seeds. Set False after seeds are produced.\n",
        "RUN_LLM_STRUCT = False        # If True, attempt to use LLM to produce structured sample rows\n",
        "HF_TOKEN = \"YOUR_TOKEN\"     # Replace with your HF token if RUN_LLM True\n",
        "\n",
        "N_FINAL = 1000                # final dataset size\n",
        "SEED_STRUCT_N = 200           # structured sample rows for CTGAN training\n",
        "URGENT_PROB = 0.35            # probability a ticket is urgent in generated samples\n",
        "RNG_SEED = 42                 # reproducibility\n",
        "OUT_CSV = \"synthetic_support_tickets.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sdv transformers accelerate bitsandbytes huggingface_hub --quiet"
      ],
      "metadata": {
        "id": "D_g10Sny8CDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# SDV / CTGAN imports\n",
        "from sdv.single_table import CTGANSynthesizer\n",
        "from sdv.metadata import SingleTableMetadata\n",
        "\n",
        "# RNG\n",
        "rng = np.random.default_rng(RNG_SEED)\n",
        "\n",
        "# LLM setup (guarded)\n",
        "tokenizer = None\n",
        "model = None\n",
        "device = \"cpu\"\n",
        "\n",
        "if RUN_LLM:\n",
        "    import os\n",
        "    import torch\n",
        "    from huggingface_hub import login\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, logging as hf_logging\n",
        "\n",
        "    # login (programmatic)\n",
        "    os.environ[\"HUGGINGFACE_TOKEN\"] = HF_TOKEN\n",
        "    try:\n",
        "        login(token=HF_TOKEN)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Silence transformer info logs (prevents repeated pad messages)\n",
        "    hf_logging.set_verbosity_error()\n",
        "\n",
        "    model_name = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
        "    bnb = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False, token=os.environ.get(\"HUGGINGFACE_TOKEN\"))\n",
        "    # Ensure pad_token exists\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "    )\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "\n",
        "# Safe generate that returns only the generated text (no prompt)\n",
        "def generate_reply_only(prompt, max_new_tokens=100, retries=2):\n",
        "    \"\"\"Generate and return only the model-generated text (without the prompt).\"\"\"\n",
        "    assert RUN_LLM and model is not None and tokenizer is not None, \"LLM not enabled\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    input_len = input_ids.shape[1]\n",
        "\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        do_sample=True,\n",
        "        temperature=0.8,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        top_p=0.95\n",
        "    )\n",
        "    gen_ids = outputs[0, input_len:]\n",
        "    text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "\n",
        "    tries = 0\n",
        "    while (not text or text.strip() == \"\") and tries < retries:\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            top_p=0.95\n",
        "        )\n",
        "        gen_ids = outputs[0, input_len:]\n",
        "        text = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "        tries += 1\n",
        "\n",
        "    # Collapse whitespace/newlines into single line and return\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ],
      "metadata": {
        "id": "QHQeLKm98Ei1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper lists\n",
        "first_names = [\"Aisha\",\"Adam\",\"Nur\",\"Sanjida\",\"Hannah\",\"Ibrahim\",\"Amina\",\"Daniel\",\"Siti\",\"Ravi\",\"Wei\",\"Sara\",\"Amir\",\"Lina\"]\n",
        "product_categories = [\"Electronics\",\"Clothing\",\"Home\",\"Beauty\",\"Groceries\"]\n",
        "issue_types = [\"Payment\",\"Delivery\",\"Product\",\"Refund\",\"Other\"]\n",
        "\n",
        "def make_structured_row(i, urgent_prob=URGENT_PROB):\n",
        "    urgent = int(rng.random() < urgent_prob)\n",
        "    ticket_dt = (datetime.now() - timedelta(days=int(rng.integers(0, 90)),\n",
        "                                           seconds=int(rng.integers(0, 86400))))\n",
        "    ticket_dt_str = ticket_dt.strftime(\"%Y-%m-%d %H:%M:%S\")  # no microseconds\n",
        "    return {\n",
        "        \"ticket_id\": f\"T{i:05d}\",\n",
        "        \"customer_id\": f\"C{rng.integers(1000, 9999)}\",\n",
        "        \"ticket_date\": ticket_dt_str,\n",
        "        \"account_age_days\": int(rng.integers(30, 2000)),\n",
        "        \"num_prev_tickets\": int(rng.poisson(2) if urgent else int(rng.poisson(1))),\n",
        "        \"avg_response_time_prev\": round(float(rng.uniform(2, 48)), 2),\n",
        "        \"product_category\": random.choice(product_categories),\n",
        "        \"issue_type\": random.choice(issue_types),\n",
        "        \"priority\": \"High\" if urgent else random.choice([\"Low\", \"Medium\"]),\n",
        "        \"urgent_flag\": int(urgent)\n",
        "    }\n",
        "\n",
        "# Build sample\n",
        "structured_sample = []\n",
        "if RUN_LLM_STRUCT and RUN_LLM:\n",
        "    pass\n",
        "\n",
        "for i in range(SEED_STRUCT_N):\n",
        "    structured_sample.append(make_structured_row(i))\n",
        "\n",
        "df_seed_struct = pd.DataFrame(structured_sample)\n",
        "print(\"Structured seed shape:\", df_seed_struct.shape)\n",
        "df_seed_struct.head()"
      ],
      "metadata": {
        "id": "6lkjz40E8gGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use only structured columns for CTGAN\n",
        "ctgan_columns = [\"customer_id\",\"ticket_date\",\"account_age_days\",\n",
        "                 \"num_prev_tickets\",\"avg_response_time_prev\",\n",
        "                 \"product_category\",\"issue_type\",\"priority\",\"urgent_flag\"]\n",
        "\n",
        "df_ctgan_train = df_seed_struct[ctgan_columns].copy()\n",
        "\n",
        "# For CTGAN, ticket_date should be convertible to a numeric or categorical representation.\n",
        "# Option: convert ticket_date to \"days_ago\" integer for CTGAN, then convert back later.\n",
        "def date_to_days_ago(dt_str):\n",
        "    dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S\")\n",
        "    return (datetime.now() - dt).days\n",
        "\n",
        "df_ctgan_train[\"days_ago\"] = df_ctgan_train[\"ticket_date\"].apply(date_to_days_ago)\n",
        "df_ctgan_train = df_ctgan_train.drop(columns=[\"ticket_date\"])\n",
        "\n",
        "# Ensure correct dtypes\n",
        "df_ctgan_train[\"account_age_days\"] = df_ctgan_train[\"account_age_days\"].astype(int)\n",
        "df_ctgan_train[\"num_prev_tickets\"] = df_ctgan_train[\"num_prev_tickets\"].astype(int)\n",
        "df_ctgan_train[\"avg_response_time_prev\"] = df_ctgan_train[\"avg_response_time_prev\"].astype(float)\n",
        "df_ctgan_train[\"urgent_flag\"] = df_ctgan_train[\"urgent_flag\"].astype(int)\n",
        "\n",
        "# Build metadata\n",
        "metadata = SingleTableMetadata()\n",
        "metadata.detect_from_dataframe(df_ctgan_train)\n",
        "\n",
        "# Train CTGAN\n",
        "ctgan = CTGANSynthesizer(metadata)\n",
        "ctgan.fit(df_ctgan_train)\n",
        "\n",
        "to_generate = N_FINAL - len(df_ctgan_train)\n",
        "print(f\"Generating {to_generate} synthetic structured rows with CTGAN...\")\n",
        "synthetic_struct = ctgan.sample(to_generate)\n",
        "\n",
        "# Combine seed + synthetic\n",
        "df_struct_all = pd.concat([df_ctgan_train, synthetic_struct], ignore_index=True)\n",
        "# Reconstruct ticket_date from days_ago (randomize time-of-day)\n",
        "def days_ago_to_date(days):\n",
        "    # randomize time-of-day\n",
        "    secs = int(rng.integers(0, 86400))\n",
        "    dt = datetime.now() - timedelta(days=int(days), seconds=secs)\n",
        "    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "df_struct_all[\"ticket_date\"] = df_struct_all[\"days_ago\"].apply(days_ago_to_date)\n",
        "df_struct_all = df_struct_all.drop(columns=[\"days_ago\"])  # done\n",
        "\n",
        "# Reorder and ensure columns\n",
        "df_struct_all = df_struct_all[[\"customer_id\",\"ticket_date\",\"account_age_days\",\n",
        "                               \"num_prev_tickets\",\"avg_response_time_prev\",\n",
        "                               \"product_category\",\"issue_type\",\"priority\",\"urgent_flag\"]]\n",
        "\n",
        "# Assign ticket_id sequentially T00000..T00999 and keep consistent\n",
        "df_struct_all.insert(0, \"ticket_id\", [f\"T{i:05d}\" for i in range(len(df_struct_all))])\n",
        "\n",
        "print(\"Combined structured dataset shape:\", df_struct_all.shape)\n",
        "df_struct_all.head()"
      ],
      "metadata": {
        "id": "z9GWNyW88mn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "first_names = [\"Aisha\",\"Adam\",\"Nur\",\"Sanjida\",\"Hannah\",\"Ibrahim\",\"Amina\",\"Daniel\",\"Siti\",\"Ravi\",\"Wei\",\"Sara\",\"Amir\",\"Lina\"]\n",
        "\n",
        "PROMPT_TEMPLATE = \"\"\"You are a customer writing a support ticket for an e-commerce platform.\n",
        "Tone: {tone}\n",
        "Context: {issue_type} issue for a {product_category} item.\n",
        "Write a 1â€“2 sentence realistic ticket (avoid placeholders like [Your Name] or [Order number]).\"\"\"\n",
        "\n",
        "for idx, r in df_struct_all.reset_index(drop=True).iterrows():\n",
        "    urgent = int(r[\"urgent_flag\"])\n",
        "    tone = \"urgent and frustrated\" if urgent == 1 else \"calm and non-urgent\"\n",
        "    prompt = PROMPT_TEMPLATE.format(tone=tone, issue_type=r[\"issue_type\"], product_category=r[\"product_category\"])\n",
        "\n",
        "    # Generate ticket_text per row (unique)\n",
        "    ticket_text = generate_reply_only(prompt, max_new_tokens=100)\n",
        "\n",
        "    # Replace any leftover placeholders\n",
        "    name = random.choice(first_names)\n",
        "    order_no = f\"ORD{rng.integers(100000,999999)}\"\n",
        "    ticket_text = re.sub(r\"\\[Your Name\\]|\\{Your Name\\}\", name, ticket_text)\n",
        "    ticket_text = re.sub(r\"\\[Order number\\]|\\{Order number\\}|\\[order number\\]\", order_no, ticket_text)\n",
        "    ticket_text = \" \".join(ticket_text.split())\n",
        "\n",
        "    row = {\n",
        "        \"ticket_id\": r[\"ticket_id\"],\n",
        "        \"customer_id\": r[\"customer_id\"],\n",
        "        \"ticket_date\": r[\"ticket_date\"],\n",
        "        \"account_age_days\": int(r[\"account_age_days\"]),\n",
        "        \"num_prev_tickets\": int(r[\"num_prev_tickets\"]),\n",
        "        \"avg_response_time_prev\": float(r[\"avg_response_time_prev\"]),\n",
        "        \"product_category\": r[\"product_category\"],\n",
        "        \"issue_type\": r[\"issue_type\"],\n",
        "        \"priority\": r[\"priority\"],\n",
        "        \"ticket_text\": ticket_text,\n",
        "        \"urgent_flag\": urgent\n",
        "    }\n",
        "    rows.append(row)\n",
        "\n",
        "df_final = pd.DataFrame(rows)\n",
        "df_final.to_csv(\"synthetic_support_tickets_unique.csv\", index=False)\n",
        "print(\"Saved 1000 fully unique tickets in synthetic_support_tickets_unique.csv\")"
      ],
      "metadata": {
        "id": "0Y_JebbW83ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final.head()"
      ],
      "metadata": {
        "id": "mM5Ss-qyb9FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple EDA (Sanjida)"
      ],
      "metadata": {
        "id": "BNWyE5EzExtK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pZ_ry3mE3qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering 1 (Syarifah)"
      ],
      "metadata": {
        "id": "CSFfvFQzE39h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Kc9U1uqFDTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering 2 (Bushra)"
      ],
      "metadata": {
        "id": "0RDgqVTXFD6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Account Age Bucket\n",
        "\n",
        "def bucket_account_age(days):\n",
        "    if days < 90:\n",
        "        return \"New\"\n",
        "    elif days <= 365:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Long\"\n",
        "\n",
        "df[\"account_age_category\"] = df[\"account_age_days\"].apply(bucket_account_age)\n",
        "\n",
        "# Customer Activity Risk\n",
        "def activity_risk(row):\n",
        "    tickets = row[\"num_prev_tickets\"]\n",
        "    response = row[\"avg_response_time_prev\"]\n",
        "\n",
        "    if tickets >= 4 or response >= 36:\n",
        "        return \"High\"\n",
        "    elif tickets >= 2 or response >= 24:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\"\n",
        "\n",
        "df[\"activity_level\"] = df.apply(activity_risk, axis=1)\n",
        "\n",
        "\n",
        "df[\"account_age_category\"].value_counts()\n",
        "df[\"activity_level\"].value_counts()"
      ],
      "metadata": {
        "id": "NXzLsZu1FJrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree (Sanjida)"
      ],
      "metadata": {
        "id": "hab-U8vqFJ_y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrcN9pTvFVxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression (Syarifah)"
      ],
      "metadata": {
        "id": "q803kdylFWKa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k3AmsUZgFc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest (Bushra)"
      ],
      "metadata": {
        "id": "DoL2MQQuFdJi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rWjOcqhFglS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost (Adhia)"
      ],
      "metadata": {
        "id": "ZWaYDNsWFg2h"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDdrDfVQFlUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# k-NN (Hani)"
      ],
      "metadata": {
        "id": "y1XAGHrPFki1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IgNG1ilFpE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Comparison (Adhia)"
      ],
      "metadata": {
        "id": "C24jw-0fFpnN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSC8KvJLFv02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Interpretation & Insights (Hani)"
      ],
      "metadata": {
        "id": "sqW3K33jFwRe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ATcAHQAF1vP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}